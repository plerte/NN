{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMbtZElEjCIxQ9mgfF6fo+E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plerte/NN/blob/master/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g7Uwl5-n77w",
        "outputId": "32df3834-55f6-4365-a2e3-817beb64c7ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "x_train.shape\n",
        "plt.title(y_train[10])\n",
        "plt.imshow(x_train[10], cmap=plt.get_cmap('gray_r'))\n",
        "plt.show()\n",
        "\n",
        "label_train = y_train.reshape(60000, -1)\n",
        "x_train1 = x_train.reshape((60000,784))\n",
        "xy_train = np.empty((60000,785))\n",
        "for i in range(60000):\n",
        "  xy_train[i] = np.hstack((x_train1[i], label_train[i]))\n",
        "\n",
        "label_test = y_test.reshape(10000, -1)\n",
        "x_test1 = x_test.reshape((10000,784))\n",
        "xy_test = np.empty((10000, 785))\n",
        "for i in range(10000):\n",
        "  xy_test[i] = np.hstack((x_test1[i], label_test[i]))\n",
        "\n",
        "\n",
        "\n",
        "def display_digit(num, x, y, vector = None):\n",
        "    label = y[num]\n",
        "    image = x[num]\n",
        "    if vector is None:\n",
        "        plt.title('Example: {}  Label: {}'.format(num, label))\n",
        "        plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
        "    else:\n",
        "        plt.figure(figsize=(6,3))\n",
        "        plt.subplot(1,2,1)\n",
        "        plt.title('Real label: {}'.format(label))\n",
        "        plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
        "        plt.subplot(1,2,2)\n",
        "        thisplot = plt.bar(range(10), vector, color=\"#777777\")\n",
        "        plt.ylim([0, 1])\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        predicted_label = np.argmax(vector)\n",
        "        thisplot[predicted_label].set_color('red')\n",
        "        plt.title('Predicted label: {}'.format(predicted_label))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Flatten(input_shape=(785,)),\n",
        "tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
        "# tf.keras.layers.Dropout(0.2),\n",
        "tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),\n",
        "loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "metrics=['accuracy'])\n",
        "history = model.fit(xy_train, y_train, epochs=50, validation_data=(xy_test, y_test))\n",
        "\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "loss, acc = model.evaluate(xy_test, y_test)\n",
        "print(\"Loss = {}, accuracy = {}\".format(loss, acc))\n",
        "\n",
        "# plt.figure(figsize=(16,10))\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel(\"Sparse_categorical_crossentropy\")\n",
        "# val = plt.plot(history.epoch, history.history['val_'+'loss'],\n",
        "#                    '--', label='Val')\n",
        "# plt.plot(history.epoch, history.history[\"loss\"], color=val[0].get_color(),\n",
        "#              label='Train')\n",
        "# plt.legend()\n",
        "# plt.xlim([0,max(history.epoch)])\n",
        "# plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1258 - accuracy: 0.9605 - val_loss: 0.0442 - val_accuracy: 0.9851\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0508 - accuracy: 0.9843 - val_loss: 0.0521 - val_accuracy: 0.9850\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0387 - accuracy: 0.9879 - val_loss: 0.0466 - val_accuracy: 0.9864\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0357 - accuracy: 0.9894 - val_loss: 0.0576 - val_accuracy: 0.9844\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0302 - accuracy: 0.9912 - val_loss: 0.0347 - val_accuracy: 0.9904\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0272 - accuracy: 0.9923 - val_loss: 0.0687 - val_accuracy: 0.9854\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0253 - accuracy: 0.9935 - val_loss: 0.0541 - val_accuracy: 0.9877\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0243 - accuracy: 0.9939 - val_loss: 0.0469 - val_accuracy: 0.9896\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0248 - accuracy: 0.9942 - val_loss: 0.0656 - val_accuracy: 0.9894\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0220 - accuracy: 0.9943 - val_loss: 0.0543 - val_accuracy: 0.9898\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0202 - accuracy: 0.9954 - val_loss: 0.0926 - val_accuracy: 0.9872\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0209 - accuracy: 0.9952 - val_loss: 0.0783 - val_accuracy: 0.9894\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0187 - accuracy: 0.9958 - val_loss: 0.0496 - val_accuracy: 0.9918\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0230 - accuracy: 0.9951 - val_loss: 0.0731 - val_accuracy: 0.9908\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0135 - accuracy: 0.9968 - val_loss: 0.0655 - val_accuracy: 0.9905\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0155 - accuracy: 0.9965 - val_loss: 0.0711 - val_accuracy: 0.9916\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0196 - accuracy: 0.9962 - val_loss: 0.0608 - val_accuracy: 0.9924\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0142 - accuracy: 0.9973 - val_loss: 0.1247 - val_accuracy: 0.9874\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0190 - accuracy: 0.9965 - val_loss: 0.0963 - val_accuracy: 0.9897\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0125 - accuracy: 0.9977 - val_loss: 0.0727 - val_accuracy: 0.9919\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0166 - accuracy: 0.9972 - val_loss: 0.0844 - val_accuracy: 0.9916\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0173 - accuracy: 0.9972 - val_loss: 0.0618 - val_accuracy: 0.9935\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0119 - accuracy: 0.9976 - val_loss: 0.0690 - val_accuracy: 0.9919\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0198 - accuracy: 0.9968 - val_loss: 0.0805 - val_accuracy: 0.9915\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0126 - accuracy: 0.9979 - val_loss: 0.1092 - val_accuracy: 0.9921\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0209 - accuracy: 0.9972 - val_loss: 0.0933 - val_accuracy: 0.9919\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0113 - accuracy: 0.9981 - val_loss: 0.1202 - val_accuracy: 0.9895\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0142 - accuracy: 0.9977 - val_loss: 0.1121 - val_accuracy: 0.9905\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0165 - accuracy: 0.9977 - val_loss: 0.0935 - val_accuracy: 0.9920\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0121 - accuracy: 0.9981 - val_loss: 0.1462 - val_accuracy: 0.9897\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0183 - accuracy: 0.9977 - val_loss: 0.1025 - val_accuracy: 0.9920\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0159 - accuracy: 0.9981 - val_loss: 0.0986 - val_accuracy: 0.9928\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0167 - accuracy: 0.9980 - val_loss: 0.1151 - val_accuracy: 0.9911\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0123 - accuracy: 0.9983 - val_loss: 0.1216 - val_accuracy: 0.9913\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0099 - accuracy: 0.9985 - val_loss: 0.1219 - val_accuracy: 0.9915\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0137 - accuracy: 0.9983 - val_loss: 0.1221 - val_accuracy: 0.9906\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0155 - accuracy: 0.9981 - val_loss: 0.1272 - val_accuracy: 0.9917\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0157 - accuracy: 0.9980 - val_loss: 0.1411 - val_accuracy: 0.9913\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0098 - accuracy: 0.9987 - val_loss: 0.1377 - val_accuracy: 0.9905\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0121 - accuracy: 0.9985 - val_loss: 0.1590 - val_accuracy: 0.9905\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0134 - accuracy: 0.9985 - val_loss: 0.1894 - val_accuracy: 0.9889\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0128 - accuracy: 0.9983 - val_loss: 0.1252 - val_accuracy: 0.9928\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0122 - accuracy: 0.9986 - val_loss: 0.1282 - val_accuracy: 0.9926\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0145 - accuracy: 0.9984 - val_loss: 0.1365 - val_accuracy: 0.9913\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0144 - accuracy: 0.9984 - val_loss: 0.1618 - val_accuracy: 0.9905\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0119 - accuracy: 0.9986 - val_loss: 0.0942 - val_accuracy: 0.9934\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0090 - accuracy: 0.9990 - val_loss: 0.1073 - val_accuracy: 0.9928\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0133 - accuracy: 0.9986 - val_loss: 0.1292 - val_accuracy: 0.9931\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0204 - accuracy: 0.9982 - val_loss: 0.1658 - val_accuracy: 0.9910\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0071 - accuracy: 0.9990 - val_loss: 0.1570 - val_accuracy: 0.9926\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.1570 - accuracy: 0.9926\n",
            "Loss = 0.1569964587688446, accuracy = 0.9926000237464905\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}